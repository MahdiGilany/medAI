{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fs01/home/abbasgln/codes/medAI/projects/tta\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Loading environment variables\n",
    "load_dotenv()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import typing as tp\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataclasses import dataclass, field\n",
    "import logging\n",
    "import wandb\n",
    "\n",
    "import medAI\n",
    "from medAI.utils.setup import BasicExperiment, BasicExperimentConfig\n",
    "\n",
    "from utils.metrics import MetricCalculator\n",
    "\n",
    "from timm.optim.optim_factory import create_optimizer\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "from datasets.datasets import ExactNCT2013RFImagePatches\n",
    "from medAI.datasets.nct2013 import (\n",
    "    KFoldCohortSelectionOptions,\n",
    "    LeaveOneCenterOutCohortSelectionOptions, \n",
    "    PatchOptions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAVE_OUT='JH'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data MEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing positions: 100%|██████████| 756/756 [00:06<00:00, 115.53it/s]\n",
      "Computing positions:  87%|████████▋ | 1059/1215 [00:09<00:01, 114.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m\n\u001b[1;32m     42\u001b[0m cohort_selection_options_train\u001b[38;5;241m.\u001b[39mremove_benign_from_positive_patients \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mremove_benign_from_positive_patients_train\n\u001b[1;32m     44\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m ExactNCT2013RFImagePatches(\n\u001b[1;32m     45\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     46\u001b[0m     transform\u001b[38;5;241m=\u001b[39mTransform(augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     debug\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdebug,\n\u001b[1;32m     50\u001b[0m )\n\u001b[0;32m---> 52\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m \u001b[43mExactNCT2013RFImagePatches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcohort_selection_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcohort_selection_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m ExactNCT2013RFImagePatches(\n\u001b[1;32m     61\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     62\u001b[0m     transform\u001b[38;5;241m=\u001b[39mTransform(augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     debug\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdebug,\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     69\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     70\u001b[0m     train_ds, batch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     71\u001b[0m )\n",
      "File \u001b[0;32m/fs01/home/abbasgln/codes/medAI/projects/tta/datasets/datasets.py:284\u001b[0m, in \u001b[0;36mExactNCT2013RFImagePatches.__init__\u001b[0;34m(self, split, transform, prescale_image, cohort_selection_options, patch_options, debug)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    274\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     debug: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    280\u001b[0m ):\n\u001b[1;32m    281\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m ExactNCT2013RFImagesWithAutomaticProstateSegmentation(\n\u001b[1;32m    282\u001b[0m         split, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cohort_selection_options\u001b[38;5;241m=\u001b[39mcohort_selection_options, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrf_image\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprescale_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprescale_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/fs01/home/abbasgln/codes/medAI/projects/tta/datasets/datasets.py:221\u001b[0m, in \u001b[0;36m_ExactNCTPatchesDataset.__init__\u001b[0;34m(self, dataset, item_name_for_patches, prescale_image, transform, patch_options, debug)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing positions\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    220\u001b[0m     positions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_positions\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 221\u001b[0m     positions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_mask_intersections\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprostate_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprostate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m46.06\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprostate_mask_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositions\u001b[38;5;241m.\u001b[39mappend(positions)\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/site-packages/medAI/datasets/nct2013.py:547\u001b[0m, in \u001b[0;36mcompute_mask_intersections\u001b[0;34m(position_data, mask, mask_name, mask_physical_shape, threshold)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition_data is a dictionary with keys \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \n\u001b[0;32m--> 547\u001b[0m position_data \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m position_datum \u001b[38;5;129;01min\u001b[39;00m position_data:\n\u001b[1;32m    550\u001b[0m     xmin, ymin, xmax, ymax \u001b[38;5;241m=\u001b[39m position_datum[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m y \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### No support dataset ######\n",
    "\n",
    "from vicreg_pretrain_experiment import PretrainConfig\n",
    "config = PretrainConfig(cohort_selection_config=LeaveOneCenterOutCohortSelectionOptions(leave_out=f\"{LEAVE_OUT}\"))\n",
    "\n",
    "from baseline_experiment import BaselineConfig\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision.tv_tensors import Image as TVImage\n",
    "\n",
    "class Transform:\n",
    "    def __init__(selfT, augment=False):\n",
    "        selfT.augment = augment\n",
    "        selfT.size = (256, 256)\n",
    "        # Augmentation\n",
    "        selfT.transform = T.Compose([\n",
    "            T.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
    "            T.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0.5),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomVerticalFlip(p=0.5),\n",
    "        ])  \n",
    "    \n",
    "    def __call__(selfT, item):\n",
    "        patch = item.pop(\"patch\")\n",
    "        patch = copy(patch)\n",
    "        patch = (patch - patch.min()) / (patch.max() - patch.min()) \\\n",
    "            if config.instance_norm else patch\n",
    "        patch = TVImage(patch)\n",
    "        patch = T.Resize(selfT.size, antialias=True)(patch).float()\n",
    "        \n",
    "        label = torch.tensor(item[\"grade\"] != \"Benign\").long()\n",
    "        \n",
    "        if selfT.augment:\n",
    "            patch_augs = torch.stack([selfT.transform(patch) for _ in range(2)], dim=0)\n",
    "            return patch_augs, patch, label, item\n",
    "        \n",
    "        return -1, patch, label, item\n",
    "\n",
    "\n",
    "cohort_selection_options_train = copy(config.cohort_selection_config)\n",
    "cohort_selection_options_train.min_involvement = config.min_involvement_train\n",
    "cohort_selection_options_train.benign_to_cancer_ratio = config.benign_to_cancer_ratio_train\n",
    "cohort_selection_options_train.remove_benign_from_positive_patients = config.remove_benign_from_positive_patients_train\n",
    "\n",
    "train_ds = ExactNCT2013RFImagePatches(\n",
    "    split=\"train\",\n",
    "    transform=Transform(augment=False),\n",
    "    cohort_selection_options=cohort_selection_options_train,\n",
    "    patch_options=config.patch_config,\n",
    "    debug=config.debug,\n",
    ")\n",
    "\n",
    "val_ds = ExactNCT2013RFImagePatches(\n",
    "    split=\"val\",\n",
    "    transform=Transform(augment=False),\n",
    "    cohort_selection_options=config.cohort_selection_config,\n",
    "    patch_options=config.patch_config,\n",
    "    debug=config.debug,\n",
    ")\n",
    "\n",
    "test_ds = ExactNCT2013RFImagePatches(\n",
    "    split=\"test\",\n",
    "    transform=Transform(augment=False),\n",
    "    cohort_selection_options=config.cohort_selection_config,\n",
    "    patch_options=config.patch_config,\n",
    "    debug=config.debug,\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=config.batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=config.batch_size, shuffle=False, num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=config.batch_size, shuffle=False, num_workers=4\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vicreg_pretrain_experiment import TimmFeatureExtractorWrapper\n",
    "from timm.layers.adaptive_avgmax_pool import SelectAdaptivePool2d\n",
    "\n",
    "\n",
    "fe_config = config.model_config\n",
    "\n",
    "# Create the model\n",
    "model: nn.Module = timm.create_model(\n",
    "    fe_config.model_name,\n",
    "    num_classes=fe_config.num_classes,\n",
    "    in_chans=1,\n",
    "    features_only=fe_config.features_only,\n",
    "    norm_layer=lambda channels: nn.GroupNorm(\n",
    "                    num_groups=fe_config.num_groups,\n",
    "                    num_channels=channels\n",
    "                    ))\n",
    "\n",
    "# Separate creation of classifier and global pool from feature extractor\n",
    "global_pool = SelectAdaptivePool2d(\n",
    "    pool_type='avg',\n",
    "    flatten=True,\n",
    "    input_fmt='NCHW',\n",
    "    )\n",
    "\n",
    "model = nn.Sequential(TimmFeatureExtractorWrapper(model), global_pool)\n",
    "\n",
    "\n",
    "# CHECkPOINT_PATH = os.path.join(os.getcwd(), f'logs/tta/vicreg_pretrain_gn_loco/vicreg_pretrain_gn_loco_{LEAVE_OUT}/', 'best_model.ckpt')\n",
    "CHECkPOINT_PATH = os.path.join(os.getcwd(), f'logs/tta/vicreg_pretrn_5e-3-20linprob_gn_loco/vicreg_pretrn_5e-3-20linprob_gn_loco_{LEAVE_OUT}/', 'best_model.ckpt')\n",
    "\n",
    "model.load_state_dict(torch.load(CHECkPOINT_PATH)['model'])\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "a = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run train linear eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4ad47f5e18419092545c428415c5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.linear_prob import LinearProb\n",
    "\n",
    "loader = train_loader\n",
    "\n",
    "desc = \"train\"\n",
    "\n",
    "# linear_prob = nn.Linear(512, 2).cuda()\n",
    "# optimizer = optim.Adam(linear_prob.parameters(), lr=1e-4)\n",
    "all_reprs_labels_metadata_train = []\n",
    "for i, batch in enumerate(tqdm(loader, desc=desc)):\n",
    "    images_augs, images, labels, meta_data = batch\n",
    "    images_augs = images_augs.cuda()\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    reprs = model(images).detach()\n",
    "    all_reprs_labels_metadata_train.append((reprs, labels, meta_data))\n",
    "\n",
    "    # logits = linear_prob(reprs)\n",
    "    # loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "    \n",
    "    # optimizer.zero_grad()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_linear_prob:   0%|          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_linear_prob: 100%|██████████| 932/932 [00:21<00:00, 42.61it/s] \n",
      "train_linear_prob: 100%|██████████| 932/932 [00:01<00:00, 693.27it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:01<00:00, 515.21it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:01<00:00, 681.74it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:01<00:00, 680.41it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:01<00:00, 468.87it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:01<00:00, 677.84it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:01<00:00, 690.04it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:01<00:00, 685.67it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:02<00:00, 440.45it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:01<00:00, 680.69it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:01<00:00, 680.97it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:01<00:00, 669.38it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:02<00:00, 386.81it/s]\n",
      "train_linear_prob: 100%|██████████| 932/932 [00:01<00:00, 689.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "metric_calculator = MetricCalculator()\n",
    "linear_prob: LinearProb = LinearProb(512, 2, metric_calculator=metric_calculator, log_wandb=False)\n",
    "linear_prob.train(all_reprs_labels_metadata_train,\n",
    "                  epochs=15,\n",
    "                  lr=5e-3\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474d727f076544c6885de4629e15f64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/726 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_linear_prob: 100%|██████████| 726/726 [00:01<00:00, 695.98it/s]\n",
      "train_linear_prob: 100%|██████████| 726/726 [00:01<00:00, 682.51it/s]\n",
      "train_linear_prob: 100%|██████████| 726/726 [00:01<00:00, 688.31it/s]\n",
      "train_linear_prob: 100%|██████████| 726/726 [00:41<00:00, 17.44it/s] \n",
      "train_linear_prob: 100%|██████████| 726/726 [00:01<00:00, 699.63it/s]\n",
      "train_linear_prob: 100%|██████████| 726/726 [00:01<00:00, 693.29it/s]\n",
      "train_linear_prob: 100%|██████████| 726/726 [00:01<00:00, 680.14it/s]\n",
      "train_linear_prob: 100%|██████████| 726/726 [00:01<00:00, 464.67it/s]\n",
      "train_linear_prob: 100%|██████████| 726/726 [00:01<00:00, 689.62it/s]\n",
      "train_linear_prob: 100%|██████████| 726/726 [00:01<00:00, 682.90it/s]\n",
      "test_linear_prob: 100%|██████████| 726/726 [00:00<00:00, 1418.64it/s]\n"
     ]
    }
   ],
   "source": [
    "loader = val_loader\n",
    "\n",
    "desc = \"test\"\n",
    "\n",
    "metric_calculator.reset()\n",
    "all_reprs_labels_metadata_test = []\n",
    "for i, batch in enumerate(tqdm(loader, desc=desc)):\n",
    "    images_augs, images, labels, meta_data = batch\n",
    "    images_augs = images_augs.cuda()\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    reprs = model(images).detach()\n",
    "    all_reprs_labels_metadata_test.append((reprs, labels, meta_data))\n",
    "                    \n",
    "    # # Update metrics   \n",
    "    # metric_calculator.update(\n",
    "    #     batch_meta_data = meta_data,\n",
    "    #     probs = nn.functional.softmax(logits, dim=-1).detach().cpu(),\n",
    "    #     labels = labels.detach().cpu(),\n",
    "    # )\n",
    "    \n",
    "\n",
    "linear_prob.validate(all_reprs_labels_metadata_test, desc=desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test/patch_auroc': tensor(0.6423),\n",
       " 'test/patch_accuracy': tensor(0.9443),\n",
       " 'test/all_inv_patch_auroc': tensor(0.6331),\n",
       " 'test/all_inv_patch_accuracy': tensor(0.9211),\n",
       " 'test/core_auroc': tensor(0.5000),\n",
       " 'test/core_accuracy': tensor(0.9444),\n",
       " 'test/all_inv_core_auroc': tensor(0.5000),\n",
       " 'test/all_inv_core_accuracy': tensor(0.9227)}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log metrics every epoch\n",
    "metrics = metric_calculator.get_metrics()\n",
    "\n",
    "# Update best score\n",
    "(\n",
    "    best_score_updated,\n",
    "    best_score\n",
    "    ) = metric_calculator.update_best_score(metrics, desc)\n",
    "\n",
    "best_score_updated = copy(best_score_updated)\n",
    "best_score = copy(best_score)\n",
    "        \n",
    "# Log metrics\n",
    "metrics_dict = {\n",
    "    f\"{desc}/{key}\": value for key, value in metrics.items()\n",
    "    }\n",
    "metrics_dict.update(best_score) if desc == \"val\" else None \n",
    "\n",
    "\n",
    "# wandb.log(\n",
    "#     metrics_dict,\n",
    "#     )\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "group=f\"offline_vicreg_finetune_gn_loco\"\n",
    "name= group + f\"_{LEAVE_OUT}\"\n",
    "wandb.init(project=\"tta\", entity=\"mahdigilany\", name=name, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e410c1f7d294a84a0a90d80abca2d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.017 MB of 0.017 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>test/all_inv_core_accuracy</td><td>▁</td></tr><tr><td>test/all_inv_core_auroc</td><td>▁</td></tr><tr><td>test/all_inv_patch_accuracy</td><td>▁</td></tr><tr><td>test/all_inv_patch_auroc</td><td>▁</td></tr><tr><td>test/core_accuracy</td><td>▁</td></tr><tr><td>test/core_auroc</td><td>▁</td></tr><tr><td>test/patch_accuracy</td><td>▁</td></tr><tr><td>test/patch_auroc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>test/all_inv_core_accuracy</td><td>0.7422</td></tr><tr><td>test/all_inv_core_auroc</td><td>0.72766</td></tr><tr><td>test/all_inv_patch_accuracy</td><td>0.66819</td></tr><tr><td>test/all_inv_patch_auroc</td><td>0.65275</td></tr><tr><td>test/core_accuracy</td><td>0.76589</td></tr><tr><td>test/core_auroc</td><td>0.8132</td></tr><tr><td>test/patch_accuracy</td><td>0.68636</td></tr><tr><td>test/patch_auroc</td><td>0.72705</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">offline_memo_2aug_gn_loco_CRCEO</strong> at: <a href='https://wandb.ai/mahdigilany/tta/runs/cysluyl7' target=\"_blank\">https://wandb.ai/mahdigilany/tta/runs/cysluyl7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240111_120559-cysluyl7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# os.environ[\"WANDB_MODE\"] = \"enabled\"\n",
    "metrics_dict.update({\"epoch\": 0})\n",
    "wandb.log(\n",
    "    metrics_dict,\n",
    "    )\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New file descriptor limits - Soft: 4096, Hard: 4096\n"
     ]
    }
   ],
   "source": [
    "import resource\n",
    "\n",
    "def increase_file_descriptor_limit(new_limit):\n",
    "    # Get the current soft and hard limits\n",
    "    soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "\n",
    "    # Set the new soft limit (cannot exceed the hard limit)\n",
    "    new_soft_limit = min(new_limit, hard)\n",
    "    resource.setrlimit(resource.RLIMIT_NOFILE, (new_soft_limit, hard))\n",
    "\n",
    "    # Verify and return the new limits\n",
    "    new_soft, new_hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "    return new_soft, new_hard\n",
    "\n",
    "# Increase the limit\n",
    "new_limit = 4096*2\n",
    "new_soft, new_hard = increase_file_descriptor_limit(new_limit)\n",
    "print(f\"New file descriptor limits - Soft: {new_soft}, Hard: {new_hard}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
