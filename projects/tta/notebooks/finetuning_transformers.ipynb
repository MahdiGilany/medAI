{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fs01/home/abbasgln/codes/medAI/projects/tta\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Loading environment variables\n",
    "load_dotenv()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import typing as tp\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataclasses import dataclass, field\n",
    "import logging\n",
    "import wandb\n",
    "\n",
    "import medAI\n",
    "from medAI.utils.setup import BasicExperiment, BasicExperimentConfig\n",
    "\n",
    "from utils.metrics import MetricCalculator, CoreMetricCalculator\n",
    "\n",
    "from timm.optim.optim_factory import create_optimizer\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "from datasets.datasets import ExactNCT2013RFImagePatches, ExactNCT2013RFCores\n",
    "from medAI.datasets.nct2013 import (\n",
    "    KFoldCohortSelectionOptions,\n",
    "    LeaveOneCenterOutCohortSelectionOptions, \n",
    "    PatchOptions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAVE_OUT='JH'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing positions: 100%|██████████| 756/756 [00:05<00:00, 143.67it/s]\n",
      "Computing positions: 100%|██████████| 616/616 [00:04<00:00, 142.88it/s]\n"
     ]
    }
   ],
   "source": [
    "###### No support dataset ######\n",
    "\n",
    "from doctest import debug\n",
    "\n",
    "from matplotlib import axis\n",
    "from vicreg_pretrain_experiment import PretrainConfig\n",
    "config = PretrainConfig(cohort_selection_config=LeaveOneCenterOutCohortSelectionOptions(leave_out=f\"{LEAVE_OUT}\"), debug=False, batch_size=1)\n",
    "\n",
    "from baseline_experiment import BaselineConfig\n",
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "class Transform:\n",
    "    def __init__(selfT, augment=False):\n",
    "        selfT.augment = augment\n",
    "        selfT.size = (256, 256)\n",
    "        # Augmentation\n",
    "        selfT.transform = T.Compose([\n",
    "            T.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
    "            T.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0.5),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomVerticalFlip(p=0.5),\n",
    "        ])  \n",
    "    \n",
    "    def __call__(selfT, item):\n",
    "        patches = item.pop(\"patches\")\n",
    "        patches = copy(patches)\n",
    "        patches = (patches - np.min(patches, axis=(-2,-1), keepdims=True)) / (np.min(patches, axis=(-2,-1), keepdims=True) - np.min(patches, axis=(-2,-1), keepdims=True)) \\\n",
    "            if config.instance_norm else patches\n",
    "        patches = torch.tensor(patches).float()\n",
    "        patches = T.Resize(selfT.size, antialias=True)(patches).float()\n",
    "        \n",
    "        label = torch.tensor(item[\"grade\"] != \"Benign\").long()\n",
    "        \n",
    "        if selfT.augment:\n",
    "            patches_augs = torch.stack([selfT.transform(patches) for _ in range(2)], dim=0)\n",
    "            return patches_augs, patches, label, item\n",
    "        \n",
    "        return -1, patches, label, item\n",
    "\n",
    "\n",
    "cohort_selection_options_train = copy(config.cohort_selection_config)\n",
    "cohort_selection_options_train.min_involvement = config.min_involvement_train\n",
    "cohort_selection_options_train.benign_to_cancer_ratio = config.benign_to_cancer_ratio_train\n",
    "cohort_selection_options_train.remove_benign_from_positive_patients = config.remove_benign_from_positive_patients_train\n",
    "\n",
    "train_ds = ExactNCT2013RFCores(\n",
    "    split=\"train\",\n",
    "    transform=Transform(augment=False),\n",
    "    cohort_selection_options=cohort_selection_options_train,\n",
    "    patch_options=config.patch_config,\n",
    "    debug=config.debug,\n",
    ")\n",
    "\n",
    "# val_ds = ExactNCT2013RFCores(\n",
    "#     split=\"val\",\n",
    "#     transform=Transform(augment=False),\n",
    "#     cohort_selection_options=config.cohort_selection_config,\n",
    "#     patch_options=config.patch_config,\n",
    "#     debug=config.debug,\n",
    "# )\n",
    "\n",
    "test_ds = ExactNCT2013RFCores(\n",
    "    split=\"test\",\n",
    "    transform=Transform(augment=True),\n",
    "    cohort_selection_options=config.cohort_selection_config,\n",
    "    patch_options=config.patch_config,\n",
    "    debug=config.debug,\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=config.batch_size, shuffle=True, num_workers=0\n",
    ")\n",
    "\n",
    "# val_loader = DataLoader(\n",
    "#     val_ds, batch_size=config.batch_size, shuffle=False, num_workers=4\n",
    "# )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=config.batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vicreg_pretrain_experiment import TimmFeatureExtractorWrapper\n",
    "from timm.layers.adaptive_avgmax_pool import SelectAdaptivePool2d\n",
    "\n",
    "\n",
    "fe_config = config.model_config\n",
    "\n",
    "# Create the model\n",
    "model: nn.Module = timm.create_model(\n",
    "    fe_config.model_name,\n",
    "    num_classes=fe_config.num_classes,\n",
    "    in_chans=1,\n",
    "    features_only=fe_config.features_only,\n",
    "    norm_layer=lambda channels: nn.GroupNorm(\n",
    "                    num_groups=fe_config.num_groups,\n",
    "                    num_channels=channels\n",
    "                    ))\n",
    "\n",
    "# Separate creation of classifier and global pool from feature extractor\n",
    "global_pool = SelectAdaptivePool2d(\n",
    "    pool_type='avg',\n",
    "    flatten=True,\n",
    "    input_fmt='NCHW',\n",
    "    )\n",
    "\n",
    "model = nn.Sequential(TimmFeatureExtractorWrapper(model), global_pool)\n",
    "\n",
    "CHECkPOINT_PATH = os.path.join(os.getcwd(), f'logs/tta/vicreg_pretrn_2048zdim_gn_loco/vicreg_pretrn_2048zdim_gn_loco_{LEAVE_OUT}/', 'best_model.ckpt')\n",
    "\n",
    "model.load_state_dict(torch.load(CHECkPOINT_PATH)['model'])\n",
    "model.cuda()\n",
    "\n",
    "a = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get train reprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num attention params 2097152\n",
      "num linear params 65730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 750/750 [00:38<00:00, 19.33it/s]\n",
      "train: 100%|██████████| 750/750 [00:40<00:00, 18.54it/s]\n",
      "train: 100%|██████████| 750/750 [00:54<00:00, 13.82it/s]\n",
      "train: 100%|██████████| 750/750 [00:43<00:00, 17.34it/s]\n",
      "train: 100%|██████████| 750/750 [00:39<00:00, 19.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'core_auroc': tensor(0.7306),\n",
       " 'core_accuracy': tensor(0.7307),\n",
       " 'all_inv_core_auroc': tensor(0.7306),\n",
       " 'all_inv_core_accuracy': tensor(0.7307)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.finetuner import AttentionFineturner, AttentionConfig\n",
    "\n",
    "metric_calculator = CoreMetricCalculator()\n",
    "attenuer_model: AttentionFineturner = AttentionFineturner(\n",
    "    feature_extractor=model,\n",
    "    feature_dim=512, \n",
    "    num_classes=2,\n",
    "    core_batch_size=10,\n",
    "    attention_config=AttentionConfig(nhead=8),\n",
    "    metric_calculator=metric_calculator,\n",
    "    log_wandb=False\n",
    "    )\n",
    "\n",
    "print(\"num attention params\", sum(p.numel() for p in attenuer_model.attention.parameters()))\n",
    "print(\"num linear params\", sum(p.numel() for p in attenuer_model.linear.parameters()))\n",
    "# attenuer_state_dict = torch.load(os.path.join(os.getcwd(), f'notebooks/attenuer_model_{LEAVE_OUT}.ckpt'))\n",
    "# attenuer_model.feature_extractor.load_state_dict(attenuer_state_dict['feature_extractor'])\n",
    "# attenuer_model.attention.load_state_dict(attenuer_state_dict['attention_head'])\n",
    "# attenuer_model.linear.load_state_dict(attenuer_state_dict['linear_head'])\n",
    "\n",
    "attenuer_model.train(train_loader,\n",
    "                  epochs=5,\n",
    "                  train_backbone=False,\n",
    "                  backbone_lr=1e-4,\n",
    "                  head_lr=1e-3,\n",
    "                  )\n",
    "metric_calculator.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(\n",
    "#     {'feature_extractor': attenuer_model.feature_extractor.state_dict(),\n",
    "#      'attention_head': attenuer_model.attention.state_dict(),\n",
    "#      'linear_head': attenuer_model.linear.state_dict(),\n",
    "#      },\n",
    "#     os.path.join(os.getcwd(), f'notebooks/attenuer_model_{LEAVE_OUT}.ckpt')\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test:  73%|███████▎  | 444/608 [00:30<00:11, 14.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mattenuer_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_memo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# attenuer_model.validate(test_loader, desc=\"test\", use_memo=True, memo_lr=5e-4)\u001b[39;00m\n",
      "File \u001b[0;32m/fs01/home/abbasgln/codes/medAI/projects/tta/models/finetuner.py:205\u001b[0m, in \u001b[0;36mAttentionFineturner.validate\u001b[0;34m(self, loader, desc, use_memo, memo_lr)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_memo:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_epoch_memo(loader, desc, memo_lr\u001b[38;5;241m=\u001b[39mmemo_lr)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/fs01/home/abbasgln/codes/medAI/projects/tta/models/finetuner.py:217\u001b[0m, in \u001b[0;36mAttentionFineturner.run_epoch\u001b[0;34m(self, loader, optimizer, scheduler, desc)\u001b[0m\n\u001b[1;32m    215\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    216\u001b[0m batch_meta_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(loader, desc\u001b[38;5;241m=\u001b[39mdesc)):\n\u001b[1;32m    218\u001b[0m     images_augs, images, labels, meta_data \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    219\u001b[0m     images_augs \u001b[38;5;241m=\u001b[39m images_augs\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/fs01/home/abbasgln/codes/medAI/projects/tta/datasets/datasets.py:529\u001b[0m, in \u001b[0;36mExactNCT2013RFCores.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    527\u001b[0m min_axial, min_lateral \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, position \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositions[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_mapping[index]]):\n\u001b[0;32m--> 529\u001b[0m     image_patch, position \u001b[38;5;241m=\u001b[39m \u001b[43mselect_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m     patches\u001b[38;5;241m.\u001b[39mappend(image_patch)\n\u001b[1;32m    531\u001b[0m     positions\u001b[38;5;241m.\u001b[39mappend(position[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m])    \n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/site-packages/medAI/datasets/nct2013.py:589\u001b[0m, in \u001b[0;36mselect_patch\u001b[0;34m(image, position_dict, patch_options)\u001b[0m\n\u001b[1;32m    585\u001b[0m ymax_mm \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m yshift\n\u001b[1;32m    587\u001b[0m position_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([xmin_mm, ymin_mm, xmax_mm, ymax_mm])\n\u001b[0;32m--> 589\u001b[0m xmin_px, ymin_px \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_physical_coordinate_to_pixel_coordinate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mxmin_mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mymin_mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m46.06\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m xmax_px, ymax_px \u001b[38;5;241m=\u001b[39m convert_physical_coordinate_to_pixel_coordinate(\n\u001b[1;32m    593\u001b[0m     (xmax_mm, ymax_mm), (\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m46.06\u001b[39m), image\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    594\u001b[0m )\n\u001b[1;32m    596\u001b[0m image_patch \u001b[38;5;241m=\u001b[39m image[xmin_px:xmax_px, ymin_px:ymax_px]\n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/site-packages/medAI/utils/image_utils.py:36\u001b[0m, in \u001b[0;36mconvert_physical_coordinate_to_pixel_coordinate\u001b[0;34m(physical_coordinates, physical_extent, pixel_extent, physical_origin, round_to_int)\u001b[0m\n\u001b[1;32m     33\u001b[0m pixel_coordinates \u001b[38;5;241m=\u001b[39m normalized_coordinates \u001b[38;5;241m*\u001b[39m pixel_extent\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m round_to_int:\n\u001b[0;32m---> 36\u001b[0m     pixel_coordinates \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_coordinates\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pixel_coordinates\n",
      "File \u001b[0;32m~/.conda/envs/mttt/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3265\u001b[0m, in \u001b[0;36m_round_dispatcher\u001b[0;34m(a, decimals, out)\u001b[0m\n\u001b[1;32m   3261\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   3262\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m asarray(a)\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m-> 3265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_round_dispatcher\u001b[39m(a, decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   3266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   3269\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_round_dispatcher)\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mround\u001b[39m(a, decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attenuer_model.validate(test_loader, desc=\"test\", use_memo=False)\n",
    "# attenuer_model.validate(test_loader, desc=\"test\", use_memo=True, memo_lr=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test/core_auroc': tensor(0.6007),\n",
       " 'test/core_accuracy': tensor(0.4074),\n",
       " 'test/all_inv_core_auroc': tensor(0.5746),\n",
       " 'test/all_inv_core_accuracy': tensor(0.4128)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log metrics every epoch\n",
    "desc = \"test\"\n",
    "metrics = metric_calculator.get_metrics()\n",
    "\n",
    "# Update best score\n",
    "(\n",
    "    best_score_updated,\n",
    "    best_score\n",
    "    ) = metric_calculator.update_best_score(metrics, desc)\n",
    "\n",
    "best_score_updated = copy(best_score_updated)\n",
    "best_score = copy(best_score)\n",
    "        \n",
    "# Log metrics\n",
    "metrics_dict = {\n",
    "    f\"{desc}/{key}\": value for key, value in metrics.items()\n",
    "    }\n",
    "metrics_dict.update(best_score) if desc == \"val\" else None \n",
    "\n",
    "\n",
    "# wandb.log(\n",
    "#     metrics_dict,\n",
    "#     )\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log with wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "group=f\"offline_vicreg_finetune_gn_loco\"\n",
    "name= group + f\"_{LEAVE_OUT}\"\n",
    "wandb.init(project=\"tta\", entity=\"mahdigilany\", name=name, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e410c1f7d294a84a0a90d80abca2d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.017 MB of 0.017 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>test/all_inv_core_accuracy</td><td>▁</td></tr><tr><td>test/all_inv_core_auroc</td><td>▁</td></tr><tr><td>test/all_inv_patch_accuracy</td><td>▁</td></tr><tr><td>test/all_inv_patch_auroc</td><td>▁</td></tr><tr><td>test/core_accuracy</td><td>▁</td></tr><tr><td>test/core_auroc</td><td>▁</td></tr><tr><td>test/patch_accuracy</td><td>▁</td></tr><tr><td>test/patch_auroc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>test/all_inv_core_accuracy</td><td>0.7422</td></tr><tr><td>test/all_inv_core_auroc</td><td>0.72766</td></tr><tr><td>test/all_inv_patch_accuracy</td><td>0.66819</td></tr><tr><td>test/all_inv_patch_auroc</td><td>0.65275</td></tr><tr><td>test/core_accuracy</td><td>0.76589</td></tr><tr><td>test/core_auroc</td><td>0.8132</td></tr><tr><td>test/patch_accuracy</td><td>0.68636</td></tr><tr><td>test/patch_auroc</td><td>0.72705</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">offline_memo_2aug_gn_loco_CRCEO</strong> at: <a href='https://wandb.ai/mahdigilany/tta/runs/cysluyl7' target=\"_blank\">https://wandb.ai/mahdigilany/tta/runs/cysluyl7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240111_120559-cysluyl7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# os.environ[\"WANDB_MODE\"] = \"enabled\"\n",
    "metrics_dict.update({\"epoch\": 0})\n",
    "wandb.log(\n",
    "    metrics_dict,\n",
    "    )\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New file descriptor limits - Soft: 4096, Hard: 4096\n"
     ]
    }
   ],
   "source": [
    "import resource\n",
    "\n",
    "def increase_file_descriptor_limit(new_limit):\n",
    "    # Get the current soft and hard limits\n",
    "    soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "\n",
    "    # Set the new soft limit (cannot exceed the hard limit)\n",
    "    new_soft_limit = min(new_limit, hard)\n",
    "    resource.setrlimit(resource.RLIMIT_NOFILE, (new_soft_limit, hard))\n",
    "\n",
    "    # Verify and return the new limits\n",
    "    new_soft, new_hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "    return new_soft, new_hard\n",
    "\n",
    "# Increase the limit\n",
    "new_limit = 4096*2\n",
    "new_soft, new_hard = increase_file_descriptor_limit(new_limit)\n",
    "print(f\"New file descriptor limits - Soft: {new_soft}, Hard: {new_hard}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
